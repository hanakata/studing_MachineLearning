データ表現のパターン

シンプルなデータ表現
    数値入力
        スケーリングが望ましい理由
            機械学習フレームワークは通常[-1,1]の範囲内の数字と適合性が高くなるように最適化手法を調整し用いる
                数値をこの範囲に収まるようスケーリングすると良い
        線形スケーリング
            データを線形的にスケーリングするもの
                min-maxスケーリング
                    数値を線形的にスケーリングする
                クリッピング
                    訓練データセットから最小値、最大値を推定する代わりに合理的な値を用いて外れ値の問題に対処
                Zスコア正規化
                    合理的な値の範囲について事前の理解を必要とせず外れ値の問題に対処
                ウィンザライズ
                    訓練データセットの経験分布を使用してデータセットをデータ値の10～90%タイルで区切られた協会にクリッピングする
        非線形変換
            一様分布のようにも正規分布のようにも分布していない場合
                入力スケーリングする前に入力に非線形変換を加える
                    入力値をスケーリングする前に入力値の対数をとる
                分布を正規分布のように見せるための線形化関数を考案するのは困難
                    簡単な方法は出力分布に適するようにバケットの境界を選択し閲覧数をパケット化すること
                        原則的な方法
                            ヒストグラム均等化
        数字の配列
            データ可変長配列を固定長の特徴量として表現する
    カテゴリ型入力
        カテゴリ型入力は数値として表す必要がある
        ワンホットエンコーディング
            カテゴリ型変数を変数の独立性を確保しつつマッピングする最もシンプルな方法
        カテゴリ型変数の配列
            カウント及び相対度数が最も一般的なイディオム

デザインパターン1:特徴量ハッシュ
    カテゴリ型の特徴量を扱う上で典型的な問題として語彙が不完全な場合や値の種類数を伴うモデルの規模の増大、さらにはコールドスタートの問題を解決
    問題
        カテゴリ型の入力変数をワンホットエンコーディングで扱うには事前に語彙を把握する必要がある
        問題はいくつか
            語彙を訓練データから把握する必要がある
            カテゴリ型変数はしばしば多くの値の種類をとる
            コールドスタート問題
    解決
        カテゴリ型の入力をそれぞれだたの一つの文字列に変換する
        疑似乱数のシードとなる初期値やソルトを用いず決定的で訓練と運用の両方で利用できる可搬性を持ったハッシュ化アルゴリズムを文字列に適用する
        ハッシュ化した結果を希望の分割数としてのバケット数で割った余りを用いる
    上手くいく理由