機械学習システムへの攻撃

学習システムの脅威モデル
    転移攻撃
        訓練データに関する情報やモデルのパラメータを窃取
    回避攻撃
        訓練済みモデルに正しく分類されないデータを生成
    汚染攻撃
        訓練中または訓練済みモデルに不正なデータを与えモデルの精度を低下

    攻撃の問題設定
        ホワイトボックス攻撃
        ブラックボックス攻撃

攻撃に利用できるライブラリ
    論文をもとに攻撃手法を再実装
    論文の著者が公開している実装を利用
    ライブラリを利用
        ARTを利用
            攻撃の流れ
                データセットのロード
                モデルの訓練
                モデルのラッパーインスタンス作成
                攻撃手法のインスタンス作成
                攻撃実行

転移攻撃
    モデル抽出
    モデル反転
    メンバーシップ推論
    Copycat CNN
        畳み込みニューラルネットワークを対象としたモデル抽出攻撃
回避攻撃
    対象データにノイズを加えて回避
        ノイズは小さければ小さいほうが良い
            人には分からないが機械学習システムは分かるというのが理想
    FGSM
    Carlini &　Wagner Attack
    ZOO Attack
    Adversarial Training
    Randomized Smoothing

汚染攻撃
    種類
        可用性攻撃
        バックドア攻撃
    BadNets
        畳み込みニューラルネットワークを対象としたバックドア攻撃
            訓練データのサブセットをランダムに選択する
            選択した画像にノイズを埋め込み攻撃者の指定したラベルを付加して訓練データを汚染
            汚染された訓練データを用いてモデルを訓練
    Activation Clustering
        BadNetsなどの手法で埋め込まれたトリガー検知が目的

用語